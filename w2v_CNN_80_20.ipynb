{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2v CNN 80/20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJiSh1+Ioks1XzdRLHXU2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilufayeasmin299/Covid19-twitter-data-analysis-using-80-20-sploting-techniques/blob/main/w2v_CNN_80_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYzfOKGVFmLl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0QaJWtXFnIH"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/gdrive/My Drive/project for paper /dataset/tencities_15days_april.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "tCerINivF4s3",
        "outputId": "c9faeff7-650d-4e2d-ccdb-62b531099af0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>twitteDate</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>loc</th>\n",
              "      <th>user_id</th>\n",
              "      <th>verified</th>\n",
              "      <th>CleanedText</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Analysis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>1245138809454395392</td>\n",
              "      <td>2020-04-01 00:00:00+00:00</td>\n",
              "      <td>thebsimone during corona stay clean fuck free ...</td>\n",
              "      <td>CA</td>\n",
              "      <td>u282394</td>\n",
              "      <td>0</td>\n",
              "      <td>thebsimon corona stay clean fuck free manit ki...</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>-0.005556</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>1245138809920126983</td>\n",
              "      <td>2020-04-01 00:00:00+00:00</td>\n",
              "      <td>balance joining fight against corona turning s...</td>\n",
              "      <td>CA</td>\n",
              "      <td>u460114</td>\n",
              "      <td>0</td>\n",
              "      <td>balanc join fight corona turn shoe product med...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>1245138828622471168</td>\n",
              "      <td>2020-04-01 00:00:04+00:00</td>\n",
              "      <td>tory lanez asked young thug been staying coron...</td>\n",
              "      <td>WA</td>\n",
              "      <td>u127769</td>\n",
              "      <td>0</td>\n",
              "      <td>tori lanez ask young thug stay coronafre respo...</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>1245138837057216518</td>\n",
              "      <td>2020-04-01 00:00:06+00:00</td>\n",
              "      <td>hasanthehun donald trump already trying spin c...</td>\n",
              "      <td>FL</td>\n",
              "      <td>u457103</td>\n",
              "      <td>0</td>\n",
              "      <td>hasanthehun donald trump alreadi tri spin coro...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>1245138844766416896</td>\n",
              "      <td>2020-04-01 00:00:08+00:00</td>\n",
              "      <td>ghastly corona found into life affected family...</td>\n",
              "      <td>TX</td>\n",
              "      <td>u616396</td>\n",
              "      <td>0</td>\n",
              "      <td>ghast corona found life affect famili lost ano...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   twitteDate             tweet_id  ...  Polarity  Analysis\n",
              "0  2020-04-01  1245138809454395392  ... -0.005556  Negative\n",
              "1  2020-04-01  1245138809920126983  ...  0.000000   Neutral\n",
              "2  2020-04-01  1245138828622471168  ...  0.100000  Positive\n",
              "3  2020-04-01  1245138837057216518  ...  0.000000   Neutral\n",
              "4  2020-04-01  1245138844766416896  ...  0.000000   Neutral\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq58Fk3YF7As",
        "outputId": "c7c4280f-09c7-4417-8aa3-55b2c2db19d8"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['twitteDate', 'tweet_id', 'created_at', 'text', 'loc', 'user_id',\n",
              "       'verified', 'CleanedText', 'Subjectivity', 'Polarity', 'Analysis'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkdm3MCGF-I8"
      },
      "source": [
        "data=df.drop(['twitteDate','tweet_id','created_at','text','loc','user_id','verified','Subjectivity','Polarity'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "aYjsvF0pGBXB",
        "outputId": "fcda9469-124a-4ff2-a6b4-7288ee6f2739"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CleanedText</th>\n",
              "      <th>Analysis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thebsimon corona stay clean fuck free manit ki...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>balanc join fight corona turn shoe product med...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tori lanez ask young thug stay coronafre respo...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hasanthehun donald trump alreadi tri spin coro...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ghast corona found life affect famili lost ano...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         CleanedText  Analysis\n",
              "0  thebsimon corona stay clean fuck free manit ki...  Negative\n",
              "1  balanc join fight corona turn shoe product med...   Neutral\n",
              "2  tori lanez ask young thug stay coronafre respo...  Positive\n",
              "3  hasanthehun donald trump alreadi tri spin coro...   Neutral\n",
              "4  ghast corona found life affect famili lost ano...   Neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjLoLi3RGDaL",
        "outputId": "2692859f-e87b-433b-89ed-0b3fd4276fa4"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(823002, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtiMHBxZGGYP"
      },
      "source": [
        "#impot all necessary libraries\n",
        "import gensim.models.keyedvectors as word2vec #need to use due to depreceated model\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import LSTM, Conv1D, Dense, Flatten, MaxPooling1D, Dropout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2G_e7UJGJm8"
      },
      "source": [
        "# Creat the function to get label of the dataset\n",
        "def getSentiment(Analysis):\n",
        "    if Analysis== 'Negative':\n",
        "        return 0\n",
        "    elif Analysis == 'Positive':\n",
        "        return 1\n",
        "    else:\n",
        "      return 2\n",
        "data['Sentiment']=data['Analysis'].apply(getSentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "q2OtQnKFGNF_",
        "outputId": "8d84e9c9-e5cc-4c81-8946-df2efd4440ff"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CleanedText</th>\n",
              "      <th>Analysis</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thebsimon corona stay clean fuck free manit ki...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>balanc join fight corona turn shoe product med...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tori lanez ask young thug stay coronafre respo...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hasanthehun donald trump alreadi tri spin coro...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ghast corona found life affect famili lost ano...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         CleanedText  Analysis  Sentiment\n",
              "0  thebsimon corona stay clean fuck free manit ki...  Negative          0\n",
              "1  balanc join fight corona turn shoe product med...   Neutral          2\n",
              "2  tori lanez ask young thug stay coronafre respo...  Positive          1\n",
              "3  hasanthehun donald trump alreadi tri spin coro...   Neutral          2\n",
              "4  ghast corona found life affect famili lost ano...   Neutral          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvabADxjGPQY"
      },
      "source": [
        "#Dividing the dataset into features and lables\n",
        "tweets = data['CleanedText']\n",
        "labels = data['Sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0oVhYAtGS-z"
      },
      "source": [
        "#Lower and split the dialog\n",
        "#and use regular expression to keep only letters we will use nltk Regular expression package\n",
        "tkr = RegexpTokenizer('[a-zA-Z@]+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf9LOCMQGVZC",
        "outputId": "2accdc6b-748a-424f-b9e8-6c104f26464c"
      },
      "source": [
        "tweets_split = []\n",
        "\n",
        "for i, line in enumerate(tweets):\n",
        "    #print(line)\n",
        "    tweet = str(line).lower().split()\n",
        "    tweet = tkr.tokenize(str(tweet))\n",
        "    tweets_split.append(tweet)\n",
        "\n",
        "print(tweets_split[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['balanc', 'join', 'fight', 'corona', 'turn', 'shoe', 'product', 'medic', 'mask', 'output', 'https']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rrmc2h1tGaWi"
      },
      "source": [
        "w2vModel = word2vec.KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/project for paper /dataset/GoogleNews-vectors-negative300.bin', binary=True, limit=510000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHa2Qer2GfCi"
      },
      "source": [
        "#Convert words to integers\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(tweets_split)\n",
        "X = tokenizer.texts_to_sequences(tweets_split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxTtuqzGGjB1",
        "outputId": "678decb5-c732-4451-967c-f6e0ce8f2686"
      },
      "source": [
        "#length of tweet to consider\n",
        "maxlentweet = 500\n",
        "#add padding\n",
        "X = pad_sequences(X, maxlen=maxlentweet)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(823002, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPqzRJH9GlqQ",
        "outputId": "1875031e-2cf6-477d-c470-d5312cfa3650"
      },
      "source": [
        "#create a embedding layer using Google pre triained word2vec (510000 words)\n",
        "embedding_layer = Embedding(input_dim=w2vModel.syn0.shape[0], output_dim=w2vModel.syn0.shape[1], weights=[w2vModel.syn0], \n",
        "                            input_length=X.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR9V7zhsGpRN"
      },
      "source": [
        "#spliting dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj9mWbvbGvlE",
        "outputId": "24e1a7fe-ee50-4ef6-811b-3926711adee2"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(658401, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhW3rPC2Gx8p",
        "outputId": "75877d8a-aa03-47c6-f9d4-dedf5da87d79"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(658401,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHW7yUPLG1Hj"
      },
      "source": [
        "num_labels=3\n",
        "batch_size=128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQIPro3GG5dZ"
      },
      "source": [
        "**Build LTSM model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh3iZybcG3M5",
        "outputId": "b0ab645d-e050-44be-a138-87a185b73810"
      },
      "source": [
        "num_labels=3\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 300)          153000000 \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 496, 128)          192128    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 153,192,515\n",
            "Trainable params: 153,192,515\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWYj1u1dG-Kn",
        "outputId": "0964d7d0-6e02-4777-8a24-cd17f2abe6f8"
      },
      "source": [
        "#fit model\n",
        "model.fit(X_train, y_train, epochs=2, verbose=1, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "5144/5144 [==============================] - 15003s 3s/step - loss: 0.1306 - accuracy: 0.9554\n",
            "Epoch 2/2\n",
            "5144/5144 [==============================] - 14968s 3s/step - loss: 0.0085 - accuracy: 0.9978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9ed542e278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BZ5juBoHDmk"
      },
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzSbSHq6a818",
        "outputId": "9c37dfa1-22d2-4ef0-d661-f0c4762397eb"
      },
      "source": [
        "from sklearn import metrics\n",
        "score = metrics.log_loss(y_test, y_pred)\n",
        "print(\"Log loss score: {}\".format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log loss score: 0.013554632246108722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELM0ejF6bBnS"
      },
      "source": [
        "import numpy as np \n",
        "y_pred= np.argmax(y_pred,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC_3NUJXbEb8",
        "outputId": "9745257a-77ca-417a-ec1e-bcee17400e8f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     43531\n",
            "           1       1.00      0.99      0.99     50604\n",
            "           2       1.00      1.00      1.00    152766\n",
            "\n",
            "    accuracy                           1.00    246901\n",
            "   macro avg       1.00      1.00      1.00    246901\n",
            "weighted avg       1.00      1.00      1.00    246901\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um1xNGS6fIk3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}